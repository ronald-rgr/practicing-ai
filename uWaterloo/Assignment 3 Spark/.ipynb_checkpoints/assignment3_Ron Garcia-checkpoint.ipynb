{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNfoXODGq4TV"
   },
   "source": [
    "## Assignment 3 - Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qMr5xQgIq4TX"
   },
   "source": [
    "## Learning Outcomes\n",
    "\n",
    "In this assignment, you will do the following:\n",
    "\n",
    "* Import Dataset to Spark Databricks environment\n",
    "\n",
    "* Create tables for data imported\n",
    "\n",
    "* Perform basic data analysis using transformations and Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GgvpSXx_q4TX"
   },
   "source": [
    "\n",
    "1. Read the article: https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html (Links to an external site.)Links to an external site. \n",
    "\n",
    "\n",
    "2. Import Data: the easiest would be to download the file from the github to your computer: https://github.com/dmatrix/examples/blob/master/spark/databricks/notebooks/py/data/iot_devices.json (Links to an external site.)Links to an external site.  and then import it to Databricks  (Note: How to import file: https://docs.databricks.com/user-guide/tables.html#create-table-ui (Links to an external site.)Links to an external site. )\n",
    "\n",
    "\n",
    "3.  You may Import Notebook below.  There is some data exploration done in this notebook for your reference.\n",
    "\n",
    "https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/5915990090493625/411609171004360/6085673883631125/latest.html\n",
    "\n",
    "- How to import notebook above. (Note: how to import notebook to Databricks: https://docs.databricks.com/user-guide/notebooks/index.html (Links to an external site.)Links to an external site. )\n",
    "\n",
    "\n",
    "4. Run it (Note: don't forget to create cluster and attached the imported notebook to it (left upper corner: button `detached`) before trying to run it.\n",
    "\n",
    "** Questions ** (12 marks) \n",
    "1. Explain the main differences between RDD, Dataframes and Datasets (4 marks)\n",
    "2. Answer following questions:\n",
    "\n",
    "   2.1 How many sensor pads are reported to be from Poland (2 marks) \n",
    "   \n",
    "   2.2 How many different lcds are present in the dataset (2 marks)  \n",
    "   \n",
    "   2.3 Find 5 countries that have the largest number of MAC devices used (2 marks)\n",
    "   \n",
    "   2.4 Introduce a new interesting analytics / algorithm you could deduct from this dataset (2 marks)\n",
    "   \n",
    "\n",
    "Note: You may use MLLib in 2.4 - https://spark.apache.org/docs/latest/ml-guide.html. Marks are awarded for idea and implementation of the analytics metric/algorithm.  \n",
    "\n",
    "Please submit the **published** notebook link in a word/pdf document.  Do not submit HTML, IPython notebook, or archive (DBC) formats.  \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 3_v2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
